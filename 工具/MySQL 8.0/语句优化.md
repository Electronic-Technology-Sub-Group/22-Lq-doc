# insert

* 批量插入：减少多次与数据库连接造成的性能损失
    * 每条 insert 语句控制在 500-1000 条
    * 若有大量数据可使用 `load`  或将多条 insert 作为一个事务提交
* 手动事务提交，避免频繁的事务开启与关闭
* 主键顺序插入，顺序插入性能高于乱序插入
* 使用 `load`  批量从文件中导入大量数据
    * 要求每条数据、每个字段之间使用一个符号分隔
    * 服务器需要一定的前置设置
	    * 连接服务器时，需要增加 `--local-infile=1`  参数
		    * JDBC：URL 使用 `jdbc//ip地址:端口/?allowLoadLocalInfile=true` 
	    * 需要全局 `local_infile`  值为 1

```mysql
set global local_infile = 1;
load data local infile '数据文件位置' into table 表名 fields terminated by '分隔符' lines terminated by '换行符' 
```

* 分隔符：每个字段之间的分隔符号
* 换行符：每条数据之间的分隔符号
# 主键优化

>[!note] IOT：InnoDB 中，表数据根据主键顺序存放，这类存储方式建立的表称为索引组织表（Index Organized Table，IOT）

> [!note] 页分裂：InnoDB 中，页可以为空，可以填充一半，也可以填充满。但每个页至少包含 2 条数据。根据这个原则，当插入的数据根据主键排序不在末尾，且所在页剩余空间无法完全容纳他时，引起页分裂现象

![[Pasted image 20240807230026.png]]

1. 所在页 1 从中间分裂成两页 1 和 3

![[Pasted image 20240807230040.png]]

2. 将待插入数据插入到正确位置

![[Pasted image 20240807230045.png]]

3. 将 3 与原本 1 后面的页 2 之间创建双向链接，将 1 与 3 之间创建双向链接

![[Pasted image 20240807230054.png]]

> [!note] 页合并
> 当删除一个数据时，不会真正删除数据，而是做一个数据废弃的标记。当删除的数据达到一定的阈值时（MERGE_THRESHOLD，默认 50%），InnoDB 自动查找上一个或下一个表，若可以合并则进行合并操作。MERGE_THRESHOLD 可以在创建表或创建索引时设定

![[Pasted image 20240807230116.png]]
![[Pasted image 20240807230121.png]]

> 主键设计原则
> * 满足需求的条件下，尽量降低主键长度，减少二级索引中主键长度，减少磁盘 IO
> * 插入时尽量按主键顺序插入，尽量选择 `auto_increment`  自增主键
> * 尽量不要使用 UUID 或身份证号等自然主键
> * 尽量不要修改主键值
# order by

MySQL 具有两种排序方式，优化主要是将 Using filesort 通过建立索引转变成 Using index
* Using index：通过有序的索引扫描直接返回数据不需要额外的排序
* Using filesort：所有不通过索引直接返回结果的排序。一般通过表索引或全表扫描，去读到满足条件的行，之后在排序缓冲区 sort buffer 中排序（超出缓冲区大小则使用磁盘文件）

尽量使使用的索引包含 order by 的键，使用联合索引且需要与联合索引的字段顺序相同，各字段排序方式全部相同或全部相反（排序方式写在字段之后，默认 asc）

```mysql
create index 索引名 on 表名(字段1 asc, 字段2 desc, ...);
```

> order by 原则：
>
> 1. 根据排序字段建立索引，多字段联合索引遵循最左前缀法则
> 2. 使用覆盖索引
> 3. 多字段排序，升序、降序不同时，联合排序需要声明 ASC DESC
> 4. 不可避免需要用到 filesort，可以在数据量较大的情况下适当提高缓冲区大小（sort_buffer_size，默认 256K）
# group by

化主要通过建立索引消灭 Using temporary

> [!warning] Using temporary：使用临时表，group by 在分组前需要建立临时表存储各自的数据。

> 1. 使用最左前缀法则建立的索引
> 2. 存在 where 条件时，联合索引 where 的字段位于左前缀
# limit

limit 返回数据第 n 到 n+k 项，当 n 很大时效率很低，MySQL 需要对前 n+k 项进行排序后返回第 n 到 n+k 项，其他数据丢弃，代价很大。

```mysql
-- 通过分页查询，查询第 9000000 到 9000010 条数据
select * from tb limit 9000000, 10;
```

使用覆盖查询+子查询/联合查询可以提高效率

```mysql
-- 1. 查找 id 第 9000000 - 9000010 条数据到表 a（id 有索引）
-- 2. 将 tb 与 a 表联合查询，条件为 tb.id = a
-- 3. 只返回 tb.* 的数据
select tb.* from tb, (select id from tb order by id limit 9000000, 10) a where tb.id = a;
```
# count

* 如果一张表只需要 `count(*)` ，使用 MyISAM，因为该表会将总行数保存在磁盘上
* 尝试自己计数（比如自己维护一个计数变量）
* 几种 count 性能，推荐使用 `count(*)`  以提高效率
    *  `count(1或任意数字)` ，`count(*)` ：遍历整张表但不取值，服务层直接累加计数
    *  `count(主键)` ，`count(not null 约束的字段)` ：取出每一条数据的值给服务层，服务层拿到数据后按行累加
    *  `count(其他字段)` ：取出每一条数据的值给服务层，服务层拿到数据后对非 NULL 数据累加
# update

事务中，按照索引字段更新表且避免索引失效，避免行锁升级为表锁降低并发性能
